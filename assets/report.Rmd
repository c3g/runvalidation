---
title: Run Report
output:
  html_document:
    keep_md: yes
    css: "style.css"
    highlight: tango
    theme: flatly
params:
  commitid: "unknown"
  version: "unknown"
---

<style type="text/css">
.main-container {
  max-width: 1280px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(magrittr)
library(reactable)
library(htmltools)
library(stringr)
library(jsonlite)
library(DT)
library(knitr)
library(formattable)
library(plotly)
library(colorspace)
library(sparkline)
library(assertthat)
```



```{r message=TRUE, warning=TRUE, include=FALSE}
# Check whether we have a demultiplexed run or a one-sample-per-lane run:
# Do we have any demux metrics files?
has.demux.metrics <- list.files(pattern = "*DemuxFastqs.metrics.txt$", recursive = T) %>% length %>% is_greater_than(0)

# Do all the validation reports contain  a "total_pf_clusters" field?
has.cluster.counts <- list.files(pattern = "*run_validation_report.json$", recursive = T, full.names = T) %>%
  lapply(read_json) %>%
  sapply(has_name, which = "total_pf_clusters") %>%
  all()

run.is.demultiplexed <- has.demux.metrics && has.cluster.counts
```


```{r message=TRUE, warning=TRUE, include=FALSE}
find.json.reports <- function() {
  pattern <- "*run_validation_report.json$"
  filenames <- list.files('.', pattern, recursive = T, full.names = T)
  assert_that(filenames %>% not_empty, msg = paste0("Could not find any validation files matching pattern \"", pattern, "\""))
  for (i in seq_along(filenames)) {
    filename <- filenames[i]
    see_if(filename %>% is.writeable, msg = paste0("Could not read file: ", filename, "."))
  }
  filenames
}

parse.json.reports.v1 <- function(filenames) {
  list.of.reports <- lapply(filenames, read_json)

  for (i in seq_along(list.of.reports)) {
    report <- list.of.reports[[i]]
    assert_that(report %has_name% 'lane',              msg = paste0("Could not find a lane number in report: '", filenames[[i]], "'"))
    assert_that(report %has_name% 'run',               msg = paste0("Could not find a run id in report: '", filenames[[i]], "'"))
    assert_that(report %has_name% 'instrument',        msg = paste0("Could not find instrument id in report: '", filenames[[i]], "'"))
    assert_that(report %has_name% 'flowcell',          msg = paste0("Could not find a flowcell id in report: '", filenames[[i]], "'"))
    assert_that(report %has_name% 'seqtype',           msg = paste0("Could not find seqtype in report: '", filenames[[i]], "'"))
    assert_that(report %has_name% 'sequencing_method',
           report$sequencing_method %in% c("PAIRED_END", "SINGLE_END"),
           msg = paste0("Could not find valid 'sequencing_method' value in report ", filenames[[i]], ". Should be 'PAIRED_END' or 'SINGLE_END'"))
  }
  list.of.reports
}

find.eventfile <- function() {
  pattern <- "*_samples.txt$"
  filename <- list.files('.', pattern, recursive = T, full.names = T)
  assert_that(filename %>% not_empty, msg = paste0("Could not find any event files matching pattern \"", pattern, "\""))
  assert_that(length(filename) < 2, msg = paste0("Found more than one event file matching pattern \"", pattern, "\""))

  filename
}

parse.eventfile.v1 <- function(filename) {
  filename %>%
    read_tsv(
      na = "N/A",
      col_types = cols(
        ProcessLUID = col_character(),
        ProjectLUID = col_character(),
        ProjectName = col_character(),
        ContainerLUID = col_character(),
        ContainerName = col_character(),
        Position = col_character(),
        Index = col_character(),
        LibraryLUID = col_character(),
        LibraryProcess = col_character(),
        ArtifactLUIDLibNorm = col_character(),
        ArtifactNameLibNorm = col_character(),
        SampleLUID = col_character(),
        SampleName = col_character(),
        Reference = col_character(),
        `Start Date` = col_date(format = ""),
        `Sample Tag` = col_character(),
        `Target Cells` = col_double(),
        `Library Metadata ID` = col_character(),
        Species = col_character(),
        `UDF/Genome Size (Mb)` = col_double(),
        Gender = col_character(),
        `Pool Fraction` = col_double(),
        `Capture Type` = col_character(),
        CaptureLUID = col_character(),
        `Capture Name` = col_character(),
        `Capture REF_BED` = col_character(),
        `Capture Metadata ID` = col_character(),
        ArtifactLUIDClustering = col_character(),
        `Library Size` = col_character(),
        `Library Kit Name` = col_character(),
        `Capture Kit Type` = col_character(),
        `Capture Bait Version` = col_character(),
        `ChIP-Seq Mark` = col_character()
      )
    ) %>%
    mutate(
      row = paste0(Index, "_lane", Position %>% gsub(":.*", "", .)),
      Lane = row %>% str_split("_lane") %>% sapply(tail, n=1) %>% as.integer(),
      Species = str_replace(Species, "N/A", "Not provided")
    ) %>%
    column_to_rownames("row")
}

get_sample_from_full_barcode_name <- function(barcodes, libraries) {
  barcodes %>% str_split(paste0("_", libraries, "_")) %>% sapply(function(row) row[1])
}

get_simple_barcode_from_full_barcode_name <- function(barcodes, libraries) {
  barcodes %>%
    str_split(paste0("_", libraries, "_")) %>%
    sapply(function(row) row[2])
}

find.demux_metrics <- function() {
  pattern <- "*DemuxFastqs.metrics.txt$"
  list.files('.', pattern, recursive = T, full.names = T)
}

parse.demux_metrics.v1 <- function(filenames) {
  if (length(filenames) == 0) {
    return(tibble())
  }
  filenames %>%
    lapply(function(filename) {
      assert_that(is.readable(filename))
      lane <- str_match(filename, "([0-9]).DemuxFastqs.metrics.txt")[, 2] %>% as.integer()
      read_tsv(
        filename,
        col_types = cols(
          barcode_name = col_character(),
          library_name = col_character(),
          barcode = col_character(),
          templates = col_double(),
          pf_templates = col_double(),
          perfect_matches = col_double(),
          pf_perfect_matches = col_double(),
          one_mismatch_matches = col_double(),
          pf_one_mismatch_matches = col_double(),
          fraction_matches = col_double(),
          ratio_this_barcode_to_best_barcode = col_double(),
          pf_fraction_matches = col_double(),
          pf_ratio_this_barcode_to_best_barcode = col_double(),
          pf_normalized_matches = col_double()
        )
      ) %>%
        mutate(
          lane = lane,
          sample = get_sample_from_full_barcode_name(barcode_name, library_name),
          barcode_simple = get_simple_barcode_from_full_barcode_name(barcode_name, library_name) %>% replace_na("unmatched"),
        )
    }) %>%
    do.call(what=rbind) %>%
    relocate(lane, library_name, sample, barcode_simple) %>%
    arrange(lane, desc(templates))
}

find.fqstats <- function() {
  pattern <- "*read_[12].fq.fqStat.txt$"
  filenames <- list.files('.', pattern, recursive = T, full.names = T)
  filenames
}

parse.fqstats <- function(filenames) {
  filenames %>%
    lapply(function(filename) {
      # Metatdata is contained in the first 12 lines
      meta <- read_tsv(filename, n_max = 12, col_names = c("key", "value")) %>%
        mutate(key = str_remove(key, "^#")) %>%
        pivot_wider(names_from = 'key') %>%
        mutate(
          Lane = str_match(filename, "_L([0-9]+)_")[, 2],
          Read = str_match(Name, "read_([12])")[, 2]
        )
    }) %>%
    do.call(what = rbind) %>%
    relocate(Lane, Read) %>%
    select(-Name) %>%
    arrange(Lane, Read) %>%
    type.convert()
}
```

```{r message=TRUE, warning=TRUE, include=FALSE}
jsons           <- find.json.reports()  %>% parse.json.reports.v1()
eventfile       <- find.eventfile()     %>% parse.eventfile.v1()
fqstats         <- find.fqstats()       %>% parse.fqstats()
if(run.is.demultiplexed) barcode_metrics <- find.demux_metrics() %>% parse.demux_metrics.v1()
```

```{r message=TRUE, warning=TRUE, include=FALSE}
if(run.is.demultiplexed) {
  runinfo <- tibble(
    "Run"                   = jsons %>% map("run")               %>% unique %>% paste(collapse = ","),
    "Sequencing Type"       = jsons %>% map("seqtype")           %>% unique %>% paste(collapse = ","),
    "Flowcell"              = jsons %>% map("flowcell")          %>% unique %>% paste(collapse=", "),
  	"Seq. Method"           = jsons %>% map("sequencing_method") %>% unique %>% paste(collapse=", "),
  	"Instrument"            = jsons %>% map("instrument")        %>% unique %>% paste(collapse=", "),
    "Total read number"     = fqstats$ReadNum %>% sum %>% divide_by(1) %>% round(1) %>% scales::comma(),
    "Total bases (Mbp)"     = fqstats$BaseNum %>% sum %>% scales::comma(scale = 1/1e6),
    "Total PF clusters(M)"  = jsons %>% map("total_pf_clusters") %>% unlist %>% sum %>% divide_by(1e6) %>% scales::comma(),
  	"Spreads"               = jsons %>% map("spread") %>% unlist %>% round(2) %>% paste(collapse=", "),
  	"Project(s)"            = jsons %>% sapply(function(json) json$run_validation %>% map("project")) %>% unlist() %>% unique %>% paste(collapse = ", ")
  	) %>% t %>% data.frame
} else {
  runinfo <- tibble(
    "Run"                   = jsons %>% map("run")               %>% unique %>% paste(collapse = ","),
    "Sequencing Type"       = jsons %>% map("seqtype")           %>% unique %>% paste(collapse = ","),
    "Flowcell"              = jsons %>% map("flowcell")          %>% unique %>% paste(collapse=", "),
  	"Seq. Method"           = jsons %>% map("sequencing_method") %>% unique %>% paste(collapse=", "),
  	"Instrument"            = jsons %>% map("instrument")        %>% unique %>% paste(collapse=", "),
    "Total read number"     = fqstats$ReadNum %>% sum %>% divide_by(1) %>% round(1) %>% scales::comma(),
    "Total bases (Mbp)"     = fqstats$BaseNum %>% sum %>% scales::comma(scale = 1/1e6),
    "Total PF clusters"     = "N/A (run not demultiplexed)",
  	"Spreads"               = "N/A (run not demultiplexed)",
  	"Project(s)"            = jsons %>% sapply(function(json) json$run_validation %>% map("project")) %>% unlist() %>% unique %>% paste(collapse = ", ")
  	) %>% t %>% data.frame
}
```


```{r include=FALSE}
rsmetrics = map(jsons,"run_validation")
names(rsmetrics) = paste0("lane", map(jsons,"lane") )
rsmetrics %<>% sapply(function(x) sapply(x,unlist,simplify=F),simplify=F)
rsmetrics %<>% sapply(function(x) do.call(rbind,x),simplify=F)
rsmetrics %<>% sapply(function(df) {data.frame(df,check.names=F)},simplify=F)
rsmetrics %<>% mapply(function(df,lane) {df$lane=lane;df},.,names(.),SIMPLIFY=F)
rsmetrics %<>% do.call(rbind,.)
rsmetrics %<>% type.convert(as.is=TRUE)

if(run.is.demultiplexed) {
  rownames(rsmetrics) = paste0(rsmetrics$"index.Barcode","_",rsmetrics$lane) # yuck # TODO: WHY MISSING S!!!
  rsmetrics %<>% cbind(eventfile[rownames(rsmetrics),])
  rsmetrics$"on_target" = ifelse(rsmetrics$"index.% of the lane"/100  >= 0.75*rsmetrics$"Pool Fraction","yes","no") # JUST a mock example of coloring...
  rsmetrics %<>% relocate(lane, project, SampleName, LibraryProcess, `index.PF Clusters`, on_target, Species, blast.1st_hit)
  rsmetrics$ReadNum <- rsmetrics[["index.PF Clusters"]]
  rsmetrics$row <- 1:nrow(rsmetrics)
} else {
  rsmetrics$Lane <- str_remove(rsmetrics$lane, "lane") %>% as.integer
  rsmetrics %<>% left_join(eventfile, by = "Lane")
  rsmetrics %<>% left_join(select(fqstats, Lane, ReadNum) %>% group_by(Lane) %>% summarise(ReadNum = sum(ReadNum)), by = "Lane")
  rsmetrics %<>% relocate(lane, project, SampleName, LibraryProcess, Species, blast.1st_hit)
}
```

## Run Processing Report {.tabset}

### Run Metrics

```{r echo=F, fig.dim=c(8, 3), messages=F, warnings=F}
kable(runinfo, col.names = c("", NULL))

if (run.is.demultiplexed) {
  rsmetrics %>%
    mutate(ID = paste0("Lane ", Lane, ": ", SampleName)) %>%
    ggplot(aes(row, ReadNum, fill=ID)) +
    geom_bar(stat="identity", alpha = 0.85) +
    ylab("Million Clusters") +
    scale_y_continuous(labels = function(x) scales::comma(x, scale = 1/1e6), limits = c(0,NA), name = "Clusters (M)") +
    theme_minimal() +
    theme(axis.title.x=element_blank(), axis.text.x = element_blank(), legend.title = element_blank()) -> plot
    ggplotly(plot)
} else {
  fqstats %>%
    group_by(Lane) %>%
    summarise(ReadNum = sum(ReadNum), BaseNum = sum(BaseNum)) %>%
    mutate("Lane name" = as.factor(Lane)) %>%
    left_join(select(eventfile, SampleName, Lane), by = 'Lane') %>%
    ggplot(aes(Lane, ReadNum, fill=`Lane name`)) +
    geom_bar(stat = "identity", alpha = 0.85) +
    scale_y_continuous(labels = function(x) scales::comma(x, scale = 1/1e6), limits = c(0,NA)) +
    theme_minimal() +
    theme(legend.position = "none") +
    ylab("Clusters (M)") -> plot
    ggplotly(plot)
}
```

```{r echo=FALSE}
clusters_bulletgraph <- function(expected, observed, max) sparkline(c(expected,observed,max,0,0), type = "bullet")

rsmetrics %>%
  group_by(lane) %>%
  mutate(
    index.expected = sum(ReadNum) / n(),
    index.max.per.lane = max(ReadNum),
    samples.per.lane = n(),
  ) %>%
  ungroup() %>%
  mutate(
    clusters.for.sparkline = mapply(function(obs, exp, max1, max2) { list(exp=exp, obs=obs, max.per.lane=max1, max.overall=max2)}, ReadNum, index.expected, index.max.per.lane, rep(max(ReadNum), n()), SIMPLIFY = FALSE),
    lane.composition.list = mapply(function(percentage, samples.per.lane) {list(percentage = percentage, samples.per.lane = samples.per.lane)}, `index.% on index in lane`, samples.per.lane, SIMPLIFY = FALSE),
    lane = gsub("lane", "Lane ", lane),
  ) -> tmp.table

if(run.is.demultiplexed) {
  tmp.table %<>%
      mutate(
    `index.% on index in lane` = `index.% on index in lane` %>% sprintf(fmt = "%.1f"),
    `index.% of the lane` = `index.% of the lane` %>% sprintf(fmt = "%.1f"),
  )
} else {
  tmp.table %<>%
      mutate(
    `index.% on index in lane` = "100%",
    `index.% of the lane` = "100%",
  )
}

tmp.table %>%
  select(
    "Lane"                 = lane,
    "Sample name"          = SampleName,
    "Clusters Graph"       = clusters.for.sparkline,
    "Clusters"             = ReadNum,
    "Lane composition"     = lane.composition.list,
    "Project"              = project,
    "Library process"      = LibraryProcess,
    "Expected species"     = Species,
    "Blast - 1st hit"      = blast.1st_hit,
    "Blast - 2nd hit"      = blast.2nd_hit,
    "Blast - 3rd hit"      = blast.3rd_hit,
  ) -> table.data

column_definitions = list(
  "Sample name" = colDef(
    minWidth = 150,
    cell = function(value, index) {
      div(
        class = "sample",
        div(class = "sample-name", value),
        div(class = "project-name", table.data[[index, "Library process"]])
      )
    }
  ),
  "Library process" = colDef(show = FALSE),
  "Lane composition" = colDef(
    minWidth = 130,
    cell = function(lst) {
      value <- lst$percentage %>% as.numeric()
      expected <- 100 / lst$samples.per.lane
      margin <- expected * 0.1
      class <- ifelse(abs(value-expected) < margin, "ok", "warn") %>%
        paste0("tag status-",.)
      div(class = class, value %>% sprintf(fmt = "%.1f%%"))
    }
  ),
  "Clusters" = colDef(
    minWidth = 100,
    cell = function(v) { scales::comma(v)}
  ),
  "Clusters Graph" = colDef(
    name = "",
    width = 100,
    sortable = FALSE,
    cell = function(l) {
      sparkline(
        c(l$exp, l$obs, l$max.overall, l$max.per.lane, 0),
        type = "bullet",
        width = "100px",
        targetColor = "#27ae60",
        targetWidth = 1,
        performanceColor = "#2980b9",
        rangeColors = c('#ecf0f100', '#ecf0f100', '#ecf0f100')
      )
    }
  ),
  "Blast - 1st hit" = colDef(
    minWidth = 200,
    name = "Blast hits",
    cell = function(value, index) {
      match.1st <- str_match(value, "(.*) (\\(\\d+\\))")
      match.2nd <- str_match(table.data[index,"Blast - 2nd hit"], "(.*) (\\(\\d+\\))")
      match.3rd <- str_match(table.data[index,"Blast - 3rd hit"], "(.*) (\\(\\d+\\))")
      div(
        class = "blast-results",
        div(
          class="blast-top",
          span(class = "name", match.1st[,2]),
          span(class = "hit-count", match.1st[,3])
        ),
        div(
          class="blast-other",
            span(class = "name", match.2nd[,2]),
          span(class = "hit-count", match.2nd[,3])
        ),
        div(
          class="blast-other",
          span(class = "name", match.3rd[,2]),
          span(class = "hit-count", match.3rd[,3])
        )
      )
    }
  ),
  "Blast - 2nd hit"   = colDef(show = FALSE),
  "Blast - 3rd hit"   = colDef(show = FALSE),
  "Library process"   = colDef(minWidth = 250),
  "Expected species"  = colDef(minWidth = 300),
  "Blast - 1st hit"   = colDef(minWidth = 200),
  "Blast - 2nd hit"   = colDef(minWidth = 200),
  "Blast - 3rd hit"   = colDef(minWidth = 200)
)

table.data %>% reactable(
  columns = column_definitions,
  rownames = FALSE,
  class = "samples-table",
  theme = reactableTheme(
    cellStyle = list(
      display = "flex",
      flexDirection = "column",
      justifyContent = "center"
    )
  )
)
```

### Index Metrics

```{r, fig.dim=c(8, 3), echo=F,messages=F,warnings=F}
if(run.is.demultiplexed) {
  indexinfo <- lapply(jsons, function(x) {
    lapply(x$barcodes, function(sample_lanes) {
      seq_along(sample_lanes) %>% lapply(function(mgi_index_num) {
        as_tibble(sample_lanes[[mgi_index_num]])
      }) %>% do.call(what = rbind)
    }) %>% do.call(what = rbind)
  }) %>% do.call(what = rbind) %>% select(
      SAMPLESHEET_NAME,
      LIBRARY,
      PROJECT,
      BARCODE_SEQUENCE,
      INDEX_NAME,
      INDEX1,
      INDEX2,
      ADAPTERi5,
      ADAPTERi7
    )
  kable(indexinfo, row.names = FALSE)
} else {
  "No index metrics available for runs that are not demultiplexed"
}
```

### Barcode Metrics

```{r, fig.dim=c(8, 3),echo=F,messages=F,warnings=F}
if(run.is.demultiplexed) {
  barcode_metrics %>%
    mutate(
      sample = as.factor(sample) %>% fct_relevel("unmatched", after = Inf),
      lane = paste("Lane", lane),
      ratio_this_barcode_to_best_barcode = sprintf("%.3f", ratio_this_barcode_to_best_barcode),
      pf_normalized_matches = sprintf("%.3f", pf_normalized_matches),
      templates = templates %>% scales::comma(),
      perfect_matches = perfect_matches %>% scales::comma(),
      one_mismatch_matches = one_mismatch_matches %>% scales::comma(),
      fraction_matches = fraction_matches %>% scales::percent(accuracy = 0.1, trim = FALSE),
    ) %>%
    select(
      -pf_templates,
      -pf_perfect_matches,
      -pf_one_mismatch_matches,
      -pf_fraction_matches,
      -pf_ratio_this_barcode_to_best_barcode,
      -barcode_name,
    ) %>%
    arrange(lane, sample) -> barcode_metrics_data

  barcode_metrics_data %>%
    reactable(
      defaultSorted = c("lane"),
      defaultColDef = colDef(class = "cell", headerClass = "header"),
      defaultExpanded = TRUE,
      pagination = FALSE,
      theme = reactableTheme(
        cellPadding = "2px 5px",
      ),
      columns = list(
        lane = colDef(name = "Lane", align = "left", width = 90),
        library_name = colDef(name = "Library", align = "right", width = 100),
        sample = colDef(name = "Sample", align = "right", minWidth = 175),
        barcode_simple = colDef(name = "Barcode Name", align = "right", minWidth = 125),
        barcode = colDef(name = "Barcode", align = "right"),
        templates = colDef(name = "Templates", align = "right", aggregate = JS("
        function(values, rows) {
          // input:
          //  - values: an array of all values in the group
          //  - rows: an array of row data objects for all rows in the group (optional)
          //
          // output:
          //  - an aggregated value, e.g. a comma-separated list
          return values.map(x => parseFloat(x.replace(/,/g, ''))).reduce((a, b) => a + b, 0).toString().replace(/\\B(?=(\\d{3})+(?!\\d))/g, ',')
        }
      ")),
        ratio_this_barcode_to_best_barcode = colDef(name = "Barcode:Best Barcode (ratio)", align = "right", minWidth = 150),
        perfect_matches = colDef(name = "Matches (perfect)", align = "right"),
        fraction_matches = colDef(name = "Matches (fraction)", align = "right"),
        one_mismatch_matches = colDef(name = "Matches (one mismatch)", align = "right", minWidth = 120),
        pf_normalized_matches = colDef(name = "Normalized Matches", align = "right", width = 90)
      ),
      # Emphasize borders between groups when sorting by lane
      rowClass = JS("
        function(rowInfo, state) {
          let rowClasses = [];
          // Check if row is last in lane
          const firstSorted = state.sorted[0]
          if (firstSorted && firstSorted.id === 'lane') {
            const nextRow = state.pageRows[rowInfo.viewIndex + 1]
            if (nextRow && rowInfo.row.lane !== nextRow.lane) {
              rowClasses.push('lane-last')
            }
            if (!nextRow) {
              rowClasses.push('lane-last')
            }
          }

          // Check if pf_normalized_matches is above 1
          pf_normalized_matches = parseFloat(rowInfo['row']['pf_normalized_matches'])
          if (pf_normalized_matches >1 ) {
            rowClasses.push('normalised-matches-warn')
          }

          // We want to highlight the number of reads without matches to known indices
          if (rowInfo['row']['sample'] == 'unmatched') {
            rowClasses.push('unmatched')
          }

          return rowClasses.join(' ')
        }"
      ),
    )
} else {
  "Barcode metrics not applicable for runs without demultiplexing"
}
```


## {#footer}

This report rendered `r format(Sys.Date(), format="%B %d %Y")` using [c3g/runvalidation](https://github.com/c3g/runvalidation/blob/main/resources/report.Rmd) v`r params$version`, commit: [`r substr(params$commitid,1,6)`](https://github.com/c3g/runvalidation/commit/`r params$commitid`)
